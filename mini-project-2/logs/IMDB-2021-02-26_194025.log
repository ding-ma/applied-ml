2021-02-26 19:40:25 INFO     
Only word tokenization, no other cleaning
LogisticRegression(max_itr=12000, solver='sag', tol=0.001), TfidfVectorizer()

2021-02-26 19:40:49 INFO     Starting CV 0/5 Test_Set[0:10000]
2021-02-26 19:41:00 INFO     Starting CV 1/5 Test_Set[10000:20000]
2021-02-26 19:41:10 INFO     Starting CV 2/5 Test_Set[20000:30000]
2021-02-26 19:41:21 INFO     Starting CV 3/5 Test_Set[30000:40000]
2021-02-26 19:41:32 INFO     Starting CV 4/5 Test_Set[40000:50000]
2021-02-26 19:41:42 INFO     ACC: avg: 0.89702, [0.8926, 0.9003, 0.8996, 0.8958, 0.8968]
2021-02-26 19:41:42 INFO     ERR: avg: 0.10298, [0.1074, 0.0997, 0.1004, 0.1042, 0.1032]
