{"cells":[{"cell_type":"markdown","source":"Note to devs :\")\n* link to overleaf document: https://www.overleaf.com/7882162453ngtnygcgqysw\n* take a look at TFIDF (term frequency inverse document frequency), may be useful if there is a distinction between good and bad reviews\n* bag of words (performance of this is usually lower) or write it in the paper bc it is lower\n* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n* https://github.com/shekhargulati/sentiment-analysis-python/tree/master/opinion-lexicon-English\n* N-gram list: http://phrasesinenglish.org/explorengrams.html#filterdiv (we should cite it, downloaded top 100k)\n* https://towardsdatascience.com/stemming-lemmatization-what-ba782b7c0bd8 (being tested rn)\n* https://docs.ray.io/en/latest/tune/index.html\n","metadata":{"cell_id":"00000-9b6be196-db14-411d-a096-b9a92941700b","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"# Task 1:  Acquire and preprocess the data\nSee `pre_process.ipynb` for majority of the work. It is used to create the csv where we can load here and train\n\nFor imdb dataset:\n* negative review will be mapped to 0\n* positive review will be mapped to 1\n","metadata":{"cell_id":"00001-48bbfc07-76f0-456b-bce3-c3564144318d","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00002-11bc85cb-89b5-4874-8718-260e549ebf17","deepnote_to_be_reexecuted":false,"execution_millis":3381,"source_hash":"d8744921","tags":[],"output_cleared":false,"execution_start":1614480776236,"deepnote_cell_type":"code"},"source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport itertools\nfrom random import randrange\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.utils import shuffle\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LogisticRegression\nfrom datetime import datetime\nfrom zoneinfo import ZoneInfo\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.corpus import stopwords\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.tokenize import word_tokenize\n\n\nfrom statistics import mean\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\n\n# dark theme compability\nplt.rcParams.update({\"figure.facecolor\": (1.0, 1.0, 1.0, 1)})\n\n\ndef evaluate_acc(test, pred):\n    return np.sum(pred == test) / test.shape[0]\n\ndef print_acc_err(res):\n    acc = res[0]\n    err = res[1]\n    logging.info(\"ACC: avg: {}, {}\".format(mean(acc), acc))\n    logging.info(\"ERR: avg: {}, {}\".format(mean(err), err))","execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00006-6adc08fa-d0af-4536-a9cc-5abcdd24f92d","deepnote_to_be_reexecuted":false,"execution_millis":10,"source_hash":"4bfad6ff","tags":[],"execution_start":1614170279806,"deepnote_cell_type":"code"},"source":"class BatchTraining:\n    \"\"\"\n    Batch training allows user to save memory by recycling the same variables.\n    Testing NB is memory intensive due ot the sparse matrix\n    \"\"\"\n\n    def __init__(self, X_test: np.array, y_test: np.array, vectorizer, batch_size=1000):\n        \"\"\"\n        :param X_test: dataset to test\n        :param y_test: true labels\n        :param vectorizer: vectorizer (SKL TFIDF or CounvtVect)\n        :param batch_size: size of training every time\n        \"\"\"\n        self.X = X_test\n        self.y = y_test\n        self.batch_size = batch_size\n        self.vectorizer = vectorizer\n\n    def __len__(self):\n        \"\"\"\n        :return: number of batches to train\n        \"\"\"\n        return (np.ceil(len(self.X) / float(self.batch_size))).astype(int)\n\n    def __iter__(self):\n        \"\"\"\n        Example:\n        >>> bt = BatchTraining(X,y,vec)\n        ... for X, y in bt:\n        :return: (X_test_batch, y_test_batch)\n        \"\"\"\n        for idx in range(len(self)):\n            batch_x = self.vectorizer.transform(\n                self.X[idx * self.batch_size : (idx + 1) * self.batch_size]\n            ).toarray()\n            batch_y = self.y[idx * self.batch_size : (idx + 1) * self.batch_size]\n            yield batch_x, batch_y","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Task 2: Implement Naive Bayes and k-fold cross validation","metadata":{"cell_id":"00002-5e4124b7-6630-452e-bcdd-2f9ec6dd8e92","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-7e720a15-350a-4491-b49b-6a7ad288a736","deepnote_to_be_reexecuted":false,"source_hash":"5dc83c25","execution_millis":1,"execution_start":1614438367705,"deepnote_cell_type":"code"},"source":"\nclass BernoulliBayes:\n    _alpha = 1.\n    _num_classes = 0\n    _fit = None\n\n    def __init__(self, alpha=1):\n        self._alpha = alpha\n\n    def fit(self, train_x, train_y):\n\n        self._num_classes = np.amax(train_y) + 1\n\n        # intialization of list containing count of occurrences of each class\n        class_count =  self._num_classes*[0]\n\n        #count occurences of each class\n        for i in train_y:\n            class_count[i] = 1 + class_count[i]\n\n        #initialization of matrix\n        fit = np.zeros((self._num_classes, train_x.shape[1] + 1))\n\n\n        # fills matrix with # of feature occurrences per class then divides by # of class occurrences\n        for i in range(self._num_classes):\n            for n, element in enumerate(train_y):\n                if element == i:\n                    fit[i, :-1] = train_x[n] + fit[i, :-1]\n            likelihood = (fit[i, :-1] + self._alpha)/(float(class_count[i]) + 2. * self._alpha)\n            fit[i, :-1] = likelihood\n            prior = class_count[i]/train_x.shape[0]\n            fit[i, -1] = prior\n\n        self._fit = fit\n\n    def predict(self,val_x, val_y):\n\n        res = np.zeros((self._num_classes, val_x.shape[0]), dtype=np.float32)\n\n        # adding class prior probability\n        for C in range(self._num_classes):\n            log_neg = 1 - self._fit[C, -1]\n            prior = self._fit[C, -1]\n\n            res[C] += np.log(prior/log_neg)\n\n        likelihood = self._fit[:, :-1]\n        res += np.log(likelihood) @ val_x.T\n        res += (np.log(1 - likelihood).sum(axis=1).reshape((-1, 1))) - (np.log(1 - likelihood) @ val_x.T)\n\n\n        return res.T\n\n        # print(res.T)\n        # print(\"what is this\", self._fit[:, :-1])\n\n        # predictions = []\n        # for example in res.T:\n        #     predictions.append(np.argmax(example))\n\n        # return predictions\n        # print(\"predictions\", predictions)\n\n        # print(\"accuracy: \" + str(np.sum(predictions == val_y)/len(predictions)))\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00006-a4d2d864-cf35-42de-bb84-4e2bd9f4275f","deepnote_to_be_reexecuted":false,"source_hash":"3312597b","execution_millis":1,"execution_start":1614438370729,"deepnote_cell_type":"code"},"source":"class MultiNomialBayes:\n    _alpha = 1.\n    _num_classes = 0\n    _fit = None\n\n    def __init__(self, alpha=1):\n        self._alpha = alpha\n\n    def fit(self, train_x, train_y):\n\n        #_num_classes is C in TA's code\n        self._num_classes = np.amax(train_y) + 1\n\n\n        # generates list containing a count of each class occurrence\n        #occurences is Nc in TA's code\n        class_count = self._num_classes*[0] \n\n        for i in train_y:\n            class_count[i] = 1 + class_count[i]\n\n        fit = np.zeros((self._num_classes, train_x.shape[1]+1))\n\n        # print(class_count)\n\n        # fills matrix with # of feature occurrences per class then divides by # of class occurrences\n        for i in range(self._num_classes):\n            for n, element in enumerate(train_y):\n                if element == i:\n                    fit[i, :-1] = train_x[n] + fit[i, :-1]\n\n            #filling likelihoods for each entry\n            likelihood = ((fit[i, :-1]) + self._alpha)/(float(class_count[i]) + train_x.shape[1]*self._alpha)\n            fit[i, :-1] = likelihood\n            #inserting prior in the last column of the array\n            prior = class_count[i]/train_x.shape[0]\n            fit[i, -1] = prior\n\n        \n        self._fit = fit\n\n\n    def predict(self, val_x, val_y):\n        #initializing matrix D*C\n        res = np.zeros((self._num_classes, val_x.shape[0]), dtype=np.float32)\n\n\n        for C in range(self._num_classes):\n            prior = self._fit[C, -1]\n            # prior_neg = 1 - prior\n            prior = np.log(prior)\n            res[C] += prior\n        likelihood = self._fit[:, :-1]\n        likelihood = np.log(likelihood) @ val_x.T\n        res += likelihood \n\n\n        return res.T\n\n        # predictions = []\n        # for example in res.T:\n        #     predictions.append(np.argmax(example))\n\n        # print(\"predictions\", predictions)\n\n        # print(\"accuracy: \" + str(np.sum(predictions == val_y)/len(predictions)))\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00007-d3edef7d-2dd5-4124-b5a9-b4d057d6ce9e","deepnote_to_be_reexecuted":false,"execution_millis":32,"source_hash":"bea8f6e3","tags":[],"execution_start":1614480857589,"deepnote_cell_type":"code"},"source":"class CrossVal:\n    def __init__(\n        self,\n        X: pd.Series,\n        y: pd.Series,\n        n_fold=5,\n        loss_fnc=lambda y, yh: np.mean((y - yh) ** 2),\n    ):\n        self.X = X.rename(\"X\")\n        self.y = y.rename(\"y\")\n        self.n_fold = n_fold\n        self.loss_fnc = loss_fnc\n\n    def __len__(self):\n        return (np.ceil(self.X.shape[0] / float(self.n_fold))).astype(int)\n\n    def __cross_validation_split(self):\n        for idx in range(self.n_fold):\n            s = idx * len(self)\n            e = (idx + 1) * len(self)\n            logging.info(\n                \"{} Starting CV {}/{} Test_Set[{}:{}]\".format(\n                    datetime.now(tz=ZoneInfo(key=\"America/Toronto\")).strftime(\n                        \"%Y-%m-%d %H:%M:%S\"\n                    ),\n                    idx,\n                    self.n_fold,\n                    s,\n                    e,\n                )\n            )\n\n            #  recall that drop does not affect the original dataframe unless you put inplate=True\n            x_train = self.X.drop(self.X.index[s:e])\n            y_train = self.y.drop(self.y.index[s:e])\n\n            x_test = self.X[s:e]\n            y_test = self.y[s:e]\n            yield x_train.to_numpy(), x_test.to_numpy(), y_train.to_numpy(), y_test.to_numpy()\n\n    def kfoldCV_custom_size(self, model, vectorizer, train_size):\n        \"\"\"\n        May not be able to perform the entire dataset CV.\n        But it will perform K times with a random state\n        There might be repeated datapoints in a train/test set.\n        On average it should produce the same result\n        \"\"\"\n\n        if not 0 < train_size < 1:\n            raise ValueError(\"Train size needs to be within ]0,1[\")\n\n        combined = pd.concat([self.X, self.y], axis=1)\n        kfold_acc = []\n        kfold_err = []\n        for fold in range(self.n_fold):\n            logging.info(\n                \"{} Starting CV {}/{} Train={}, Test={}\".format(\n                    datetime.now(tz=ZoneInfo(key=\"America/Toronto\")).strftime(\n                        \"%Y-%m-%d %H:%M:%S\"\n                    ),\n                    fold,\n                    self.n_fold,\n                    train_size,\n                    (1 - train_size),\n                )\n            )\n\n            test_set = combined.sample(frac=(1 - train_size))\n            train_set = combined[~combined.isin(test_set)].dropna()\n\n            x_train = train_set[\"X\"].to_numpy()\n            x_test = test_set[\"X\"].to_numpy()\n\n            y_train = train_set[\"y\"].to_numpy()\n            y_test = test_set[\"y\"].to_numpy()\n\n            model.fit(vectorizer.fit_transform(x_train), y_train)\n            y_predict = model.predict(vectorizer.transform(x_test))\n            acc = evaluate_acc(y_test, y_predict)\n            err = self.loss_fnc(y_test, y_predict)\n            kfold_acc.append(acc)\n            kfold_err.append(err)\n        return kfold_acc, kfold_err\n\n    def kfoldCV(self, model, vectorizer, **kwargs):\n        \"\"\"\n        model: NB, LR. your model needs to have fit and predict as functions at least\n        vectorizer: CV, TFIDF\n        \"\"\"\n        kfold_acc = []\n        kfold_err = []\n\n        for x_train, x_test, y_train, y_test in self.__cross_validation_split():\n            # todo: might need to use batch trainer\n            model.fit(vectorizer.fit_transform(x_train), y_train)\n            y_predict = model.predict(vectorizer.transform(x_test))\n            acc = evaluate_acc(y_test, y_predict)\n            err = self.loss_fnc(y_test, y_predict)\n            kfold_acc.append(acc)\n            kfold_err.append(err)\n        return kfold_acc, kfold_err\n\n    def repeat(self, **kwargs):\n        \"\"\"\n        *args, **kwargs\n\n        pseudo: sklearn gridsearchcv\n\n        self === this in java\n        \"\"\"\n        # done in project2-LR\n        pass\n","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Task 3: Run experiments","metadata":{"cell_id":"00003-f7fdeb96-f7ca-4987-8c8d-80a10f563eb1","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"## Load datasets","metadata":{"tags":[],"cell_id":"00009-2049225e-1a55-4f30-9585-196b0de9aa7e","deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00002-b5f4e411-4005-455c-ba30-d06451930fba","deepnote_to_be_reexecuted":false,"execution_millis":23520,"output_cleared":false,"source_hash":"c3fe759d","tags":[],"execution_start":1614436105526,"deepnote_cell_type":"code"},"source":"imdb_df = pd.read_csv(\"dataset/imdb_row_array_bigram.csv\")\n\n# keep random state so we can have a reproducable result\nimdb_df = shuffle(imdb_df, random_state=1)\n\nimdb_df[\"sentence\"] = imdb_df[\"sentence\"].apply(lambda x: \" \".join(eval(x)))\nimdb_df.loc[imdb_df[\"review_type\"] == \"pos\", \"review_type\"] = 1\nimdb_df.loc[imdb_df[\"review_type\"] == \"neg\", \"review_type\"] = 0\n\n\n# int32 is more memory efficient and enough for our needs\nimdb_df = imdb_df.astype(\n    {\"review_id\": \"int32\", \"review_type\": \"int32\", \"review_number\": \"int32\"}\n)\n\nimdb_df_X = imdb_df[\"sentence\"]\nimdb_df_y = imdb_df[\"review_type\"]\n\nimdb_df_CV = CrossVal(imdb_df_X, imdb_df_y)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-33123a6a-62e3-4ed8-aa5b-86eebcc97fef","deepnote_to_be_reexecuted":false,"source_hash":"6a12b511","execution_millis":26893,"execution_start":1614438375049,"deepnote_cell_type":"code"},"source":"X_train, X_test, y_train, y_test = train_test_split(imdb_df_X, imdb_df_y, test_size=0.33, random_state=42)\n\n\n\nbb = BernoulliBayes()\ncv =  TfidfVectorizer()\nbb.fit(cv.fit_transform(X_train),y_train)\ny_pred = bb.predict(cv.transform(X_test),y_test)\n\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00012-7488a7cf-0368-4711-bbcd-7c1bdb72c0d8","deepnote_to_be_reexecuted":false,"source_hash":"1de65a4f","execution_millis":32365,"execution_start":1614437087091,"deepnote_cell_type":"code"},"source":"res = imdb_df_CV.kfoldCV(BernoulliBayes(),TfidfVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-27 09:44:47 Starting CV 0/5 Test_Set[0:10000]\n<ipython-input-2-db58bbb0b6a1>:34: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n  return np.sum(pred == test) / test.shape[0]\n","output_type":"stream"},{"output_type":"error","ename":"ValueError","evalue":"operands could not be broadcast together with shapes (10000,) (10000,2) ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-0ad5ab89b0ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_df_CV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfoldCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBernoulliBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_acc_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d3027c37ffe5>\u001b[0m in \u001b[0;36mkfoldCV\u001b[0;34m(self, model, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m             \u001b[0mkfold_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mkfold_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d3027c37ffe5>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(y, yh)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mn_fold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mloss_fnc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myh\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0myh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     ):\n\u001b[1;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10000,) (10000,2) "]}]},{"cell_type":"code","metadata":{"cell_id":"00010-aac4d545-4394-4956-a25e-025b03e5d60f","deepnote_to_be_reexecuted":false,"execution_millis":12524,"output_cleared":false,"source_hash":"850a403","tags":[],"execution_start":1614480929134,"deepnote_cell_type":"code"},"source":"twenty_news_df = pd.read_csv(\"dataset/twenty_news_row_array_bigram.csv\")\n\ntwenty_news_df = shuffle(twenty_news_df, random_state=1)\ntwenty_news_df[\"sentence\"] = twenty_news_df[\"sentence\"].apply(\n    lambda x: \" \".join(eval(x))\n)\n\ntwenty_news_df_X = twenty_news_df[\"sentence\"]\ntwenty_news_df_y = twenty_news_df[\"target\"]\n\ntwenty_CV = CrossVal(twenty_news_df_X, twenty_news_df_y)\n\n# print(len(twenty_news_df_X))\n# print(len(twenty_news_df_y))","execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Naive Bayes","metadata":{"cell_id":"00009-abe05566-c042-42b6-b88c-7b3fb0f15d09","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### IMDB","metadata":{"cell_id":"00010-0c7f3d3d-9eaa-4961-a05e-4df97a17ebb0","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Sk-learn metrics","metadata":{"cell_id":"00004-324bd916-183c-482c-8aee-0d69600f9c02","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00015-fe818efb-780b-4bfc-af22-8d89ea33fe93","deepnote_to_be_reexecuted":false,"source_hash":"a9e066f1","execution_millis":2,"execution_start":1614051546592,"deepnote_cell_type":"code"},"source":"#  __name__ get name of the class","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"00017-f1a13f20-1af2-41f9-806c-e83cefc63916","deepnote_to_be_reexecuted":false,"source_hash":"805851f3","execution_millis":23,"execution_start":1614436129049,"deepnote_cell_type":"code"},"source":"res = imdb_df.kfoldCV(BernoulliBayes(), TfidfVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"'DataFrame' object has no attribute 'kfoldCV'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-3eeb03e8e8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfoldCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBernoulliBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_acc_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5460\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5462\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5464\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'kfoldCV'"]}]},{"cell_type":"code","metadata":{"cell_id":"00005-879da175-77ad-43bc-910b-fde5be669a07","deepnote_to_be_reexecuted":false,"execution_millis":30857,"output_cleared":false,"source_hash":"4e70407b","tags":[],"execution_start":1614436135509,"deepnote_cell_type":"code"},"source":"res = imdb_df_CV.kfoldCV(MultiNomialBayes(), TfidfVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-27 09:28:55 Starting CV 0/5 Test_Set[0:10000]\n[19939, 20061]\n","output_type":"stream"},{"output_type":"error","ename":"TypeError","evalue":"predict() missing 1 required positional argument: 'validationLabels'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-ddeb3e617353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_df_CV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfoldCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultiNomialBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint_acc_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-d3027c37ffe5>\u001b[0m in \u001b[0;36mkfoldCV\u001b[0;34m(self, model, vectorizer, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m# todo: might need to use batch trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'validationLabels'"]}]},{"cell_type":"code","metadata":{"cell_id":"00015-dcdebdbc-9f4c-4f1a-a2cf-eefe727c8ba7","deepnote_to_be_reexecuted":true,"execution_millis":104537,"source_hash":"6931b2a","tags":[],"output_cleared":false,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = imdb_df_CV.kfoldCV_custom_size(MultinomialNB(), CountVectorizer(), i)\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 04:53:37 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 04:53:48 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 04:53:59 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 04:54:10 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 04:54:21 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.858985, [0.857125, 0.861, 0.858425, 0.856925, 0.86145]\nINFO:root:ERR: avg: 0.141015, [0.142875, 0.139, 0.141575, 0.143075, 0.13855]\nINFO:root:2021-02-22 04:54:33 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 04:54:43 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 04:54:54 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 04:55:05 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 04:55:16 Starting CV 4/5 Train=0.4, Test=0.6\n","output_type":"stream"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-96a3e1f03eea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimdb_df_CV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkfoldCV_custom_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMultinomialNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint_acc_err\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-4-77849f146322>\u001b[0m in \u001b[0;36mkfoldCV_custom_size\u001b[0;34m(self, model, vectorizer, train_size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0my_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fnc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m         \u001b[0;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1117\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfeature_idx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_counter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"cell_id":"00012-eecf67dd-7df1-4a32-b54f-5a89cf07822b","deepnote_to_be_reexecuted":true,"execution_millis":57487,"source_hash":"37d07212","tags":[],"deepnote_cell_type":"code"},"source":"res = imdb_df_CV.kfoldCV(MultinomialNB(), TfidfVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:17:56 Starting CV 0/5 Test_Set[0:10000]\nINFO:root:2021-02-22 00:18:07 Starting CV 1/5 Test_Set[10000:20000]\nINFO:root:2021-02-22 00:18:19 Starting CV 2/5 Test_Set[20000:30000]\nINFO:root:2021-02-22 00:18:30 Starting CV 3/5 Test_Set[30000:40000]\nINFO:root:2021-02-22 00:18:42 Starting CV 4/5 Test_Set[40000:50000]\nINFO:root:ACC: avg: 0.8781599999999999, [0.8753, 0.8783, 0.8801, 0.8792, 0.8779]\nINFO:root:ERR: avg: 0.12184, [0.1247, 0.1217, 0.1199, 0.1208, 0.1221]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00017-33b6da2b-597f-466c-a171-2d7ad38aba14","deepnote_to_be_reexecuted":true,"execution_millis":233374,"source_hash":"cfcd0c43","tags":[],"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = imdb_df_CV.kfoldCV_custom_size(MultinomialNB(), TfidfVectorizer(), i)\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:18:53 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:19:05 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:19:17 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:19:29 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:19:41 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.86913, [0.8675, 0.865075, 0.8729, 0.8704, 0.869775]\nINFO:root:ERR: avg: 0.13087, [0.1325, 0.134925, 0.1271, 0.1296, 0.130225]\nINFO:root:2021-02-22 00:19:53 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:20:04 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:20:16 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:20:28 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:20:39 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.8738933333333333, [0.8753333333333333, 0.8750666666666667, 0.8735333333333334, 0.8688666666666667, 0.8766666666666667]\nINFO:root:ERR: avg: 0.12610666666666667, [0.12466666666666666, 0.12493333333333333, 0.12646666666666667, 0.13113333333333332, 0.12333333333333334]\nINFO:root:2021-02-22 00:20:50 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:21:01 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:21:12 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:21:24 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:21:35 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.87735, [0.8765, 0.8785, 0.87665, 0.88105, 0.87405]\nINFO:root:ERR: avg: 0.12265, [0.1235, 0.1215, 0.12335, 0.11895, 0.12595]\nINFO:root:2021-02-22 00:21:47 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:21:59 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:22:11 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:22:23 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:22:35 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.8749, [0.8755, 0.8731, 0.8753, 0.8746, 0.876]\nINFO:root:ERR: avg: 0.12510000000000002, [0.1245, 0.1269, 0.1247, 0.1254, 0.124]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Self implemented","metadata":{"cell_id":"00016-6d9a5551-5609-4376-b9f8-3be26bcb6151","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00019-bf87d0a0-696b-4447-9038-dce802344390","deepnote_to_be_reexecuted":true,"execution_millis":2,"source_hash":"2e2f898a","tags":[],"deepnote_cell_type":"code"},"source":"# todo","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Twenty News Group","metadata":{"cell_id":"00014-e6962f29-84a5-46e0-be4c-b09b6fbf6a24","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"#### Sk-learn metrics","metadata":{"cell_id":"00015-ab513ea8-578a-4980-9abd-498d6f37e85c","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00016-d3e1bf80-0fab-4148-9338-c01cf6062965","deepnote_to_be_reexecuted":true,"execution_millis":20017,"source_hash":"b0a05cb8","tags":[],"deepnote_cell_type":"code"},"source":"res = twenty_CV.kfoldCV(MultinomialNB(), CountVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:22:47 Starting CV 0/5 Test_Set[0:3770]\nINFO:root:2021-02-22 00:22:51 Starting CV 1/5 Test_Set[3770:7540]\nINFO:root:2021-02-22 00:22:55 Starting CV 2/5 Test_Set[7540:11310]\nINFO:root:2021-02-22 00:22:59 Starting CV 3/5 Test_Set[11310:15080]\nINFO:root:2021-02-22 00:23:03 Starting CV 4/5 Test_Set[15080:18850]\nINFO:root:ACC: avg: 0.6563745701804925, [0.6445623342175066, 0.6604774535809018, 0.6517241379310345, 0.659946949602122, 0.6651619755708975]\nINFO:root:ERR: avg: 18.061050499302006, [18.049071618037136, 18.614854111405837, 18.572944297082227, 17.367904509283818, 17.700477960701008]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00023-078881f4-92aa-4183-9f38-e33b6ab20be8","tags":[],"deepnote_to_be_reexecuted":true,"source_hash":"bd335ff3","execution_millis":77860,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = twenty_CV.kfoldCV_custom_size(MultinomialNB(), CountVectorizer(), i)\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:23:07 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:23:10 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:23:14 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:23:17 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:23:21 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.5381839888571998, [0.5194004112223918, 0.5582675598593885, 0.5383033760031837, 0.5340584997015322, 0.5408900974995026]\nINFO:root:ERR: avg: 23.39137759501227, [24.579624593752072, 22.45532930954434, 24.0358824699874, 23.033428400875504, 22.852623200902038]\nINFO:root:2021-02-22 00:23:24 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:23:28 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:23:32 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:23:36 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:23:40 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.6083480721613017, [0.626989741775734, 0.588698266713831, 0.6229218252564556, 0.6086841174389812, 0.5944464096215069]\nINFO:root:ERR: avg: 20.281163777856385, [20.2942164839052, 19.928015564202333, 19.579324372125928, 20.193933498408207, 21.410328970640254]\nINFO:root:2021-02-22 00:23:44 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:23:48 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:23:52 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:23:56 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:24:00 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.632979570177766, [0.621517643937384, 0.6391615813213054, 0.6407535155213584, 0.6313345715043778, 0.6321305386044044]\nINFO:root:ERR: avg: 19.814698859113825, [19.496020164499868, 19.321703369594058, 19.650570443088352, 20.563146723268773, 20.04205359511807]\nINFO:root:2021-02-22 00:24:04 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:24:08 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:24:12 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:24:16 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:24:20 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.6505173786150172, [0.6282833642876094, 0.6566728575218891, 0.6614486601220483, 0.6598567259219952, 0.6463252852215442]\nINFO:root:ERR: avg: 18.238100291854604, [18.906871849296895, 18.22711594587424, 17.42743433271425, 17.912708941363757, 18.71637039002388]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00016-882dcb5e-7899-429e-8e1e-e88df9ea2309","deepnote_to_be_reexecuted":true,"execution_millis":21461,"source_hash":"22d154ab","tags":[],"deepnote_cell_type":"code"},"source":"res = twenty_CV.kfoldCV(MultinomialNB(), TfidfVectorizer())\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:24:24 Starting CV 0/5 Test_Set[0:3770]\nINFO:root:2021-02-22 00:24:29 Starting CV 1/5 Test_Set[3770:7540]\nINFO:root:2021-02-22 00:24:33 Starting CV 2/5 Test_Set[7540:11310]\nINFO:root:2021-02-22 00:24:37 Starting CV 3/5 Test_Set[11310:15080]\nINFO:root:2021-02-22 00:24:42 Starting CV 4/5 Test_Set[15080:18850]\nINFO:root:ACC: avg: 0.6809959838904845, [0.6859416445623342, 0.6710875331564987, 0.6625994694960212, 0.6917771883289124, 0.6935740839086564]\nINFO:root:ERR: avg: 16.601933705315325, [14.774801061007958, 19.115649867374007, 18.912997347480108, 15.093633952254642, 15.112586298459904]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00025-5765f1cc-ffb2-4f92-b97f-1eac1f0c29d9","tags":[],"deepnote_to_be_reexecuted":true,"source_hash":"a482ffd","execution_millis":78182,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = twenty_CV.kfoldCV_custom_size(MultinomialNB(), TfidfVectorizer(), i)\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:24:46 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:24:50 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:24:53 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:24:57 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:25:01 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.5966969556277774, [0.6041652848709955, 0.6003846919148371, 0.5824102938250315, 0.5936857465012934, 0.6028387610267295]\nINFO:root:ERR: avg: 19.7643032433508, [21.16495324003449, 18.58539497247463, 20.756980831730452, 18.70703720899383, 19.607149963520595]\nINFO:root:2021-02-22 00:25:04 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:25:08 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:25:12 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:25:16 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:25:20 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.6386982667138309, [0.6391050583657587, 0.6549345596038203, 0.6396356561726212, 0.6370711001061196, 0.6227449593208348]\nINFO:root:ERR: avg: 17.951644853201273, [17.31623629288999, 17.613901662539796, 17.200123806154934, 18.57260346657234, 19.05535903784931]\nINFO:root:2021-02-22 00:25:24 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:25:28 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:25:32 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:25:36 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:25:40 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.6700451048023348, [0.6602547094720085, 0.6696736534889891, 0.6698063146723269, 0.6826744494560891, 0.6678163969222606]\nINFO:root:ERR: avg: 16.791721942159725, [17.194481294773148, 15.984611302732821, 17.310559830193686, 17.28256832050942, 16.186388962589547]\nINFO:root:2021-02-22 00:25:44 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:25:48 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:25:52 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:25:56 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:26:00 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.6778986468559299, [0.6792252586893075, 0.6882462191562748, 0.6733881666224463, 0.6723268771557442, 0.6763067126558769]\nINFO:root:ERR: avg: 16.90724330061024, [15.747413106924913, 16.366675510745555, 16.33749005041125, 17.63518174582117, 18.449456089148317]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### Self implemented","metadata":{"cell_id":"00021-62f18062-68d7-4050-ac9e-0706a9f927a3","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00021-94044665-0c4a-4308-bfc3-99197e372db8","deepnote_to_be_reexecuted":true,"execution_millis":0,"source_hash":"2e2f898a","tags":[],"deepnote_cell_type":"code"},"source":"# todo","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Logistic Regiossion with Sk-Learn","metadata":{"cell_id":"00015-06c86951-fc49-48e9-bc25-aaac77949713","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"TODOs:\n* test with different parameters\n* small **tol** takes forever to converge\n* docs can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n* https://stackoverflow.com/questions/20894671/speeding-up-sklearn-logistic-regression","metadata":{"cell_id":"00023-5e93cf9a-207a-4bd4-ac34-306b9870a419","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"markdown","source":"### IMDB","metadata":{"cell_id":"00016-8ae612c5-388d-46b7-8ed2-f97d4be6826d","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00017-7f09c74c-3e43-4ab2-bb40-de7c36e22ff7","deepnote_to_be_reexecuted":true,"execution_millis":161447,"output_cleared":false,"source_hash":"404aba0b","tags":[],"deepnote_cell_type":"code"},"source":"# see docs for args for LR\n\n# tol @ 1e-4 doesnt converge well\nres = imdb_df_CV.kfoldCV(\n    LogisticRegression(solver=\"newton-cg\", max_iter=1000, n_jobs=4, tol=0.01),\n    CountVectorizer(),\n)\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:26:04 Starting CV 0/5 Test_Set[0:10000]\nINFO:root:2021-02-22 00:26:38 Starting CV 1/5 Test_Set[10000:20000]\nINFO:root:2021-02-22 00:27:12 Starting CV 2/5 Test_Set[20000:30000]\nINFO:root:2021-02-22 00:27:45 Starting CV 3/5 Test_Set[30000:40000]\nINFO:root:2021-02-22 00:28:14 Starting CV 4/5 Test_Set[40000:50000]\nINFO:root:ACC: avg: 0.9011, [0.9001, 0.9048, 0.9023, 0.8956, 0.9027]\nINFO:root:ERR: avg: 0.0989, [0.0999, 0.0952, 0.0977, 0.1044, 0.0973]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00032-ea7ed28a-eecf-4a24-97b9-28884b8ccc87","tags":[],"deepnote_to_be_reexecuted":true,"source_hash":"2631210","execution_millis":460129,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = imdb_df_CV.kfoldCV_custom_size(\n        LogisticRegression(solver=\"newton-cg\", max_iter=1000, n_jobs=4, tol=0.01),\n        CountVectorizer(), i,\n    )\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:28:46 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:28:59 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:29:13 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:29:26 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:29:40 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.878375, [0.87785, 0.877775, 0.8798, 0.876775, 0.879675]\nINFO:root:ERR: avg: 0.121625, [0.12215, 0.122225, 0.1202, 0.123225, 0.120325]\nINFO:root:2021-02-22 00:29:54 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:30:13 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:30:34 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:30:52 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:31:10 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.8894733333333333, [0.8911666666666667, 0.8880333333333333, 0.8864, 0.8912333333333333, 0.8905333333333333]\nINFO:root:ERR: avg: 0.11052666666666668, [0.10883333333333334, 0.11196666666666667, 0.1136, 0.10876666666666666, 0.10946666666666667]\nINFO:root:2021-02-22 00:31:30 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:32:02 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:32:24 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:32:46 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:33:17 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.89627, [0.8949, 0.8982, 0.89315, 0.89815, 0.89695]\nINFO:root:ERR: avg: 0.10373, [0.1051, 0.1018, 0.10685, 0.10185, 0.10305]\nINFO:root:2021-02-22 00:33:47 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:34:21 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:34:55 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:35:23 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:35:55 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.89996, [0.9004, 0.8993, 0.8917, 0.9025, 0.9059]\nINFO:root:ERR: avg: 0.10004, [0.0996, 0.1007, 0.1083, 0.0975, 0.0941]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00025-0ec12474-e69d-41f4-a823-0951f5e02aa8","deepnote_to_be_reexecuted":true,"execution_millis":80441,"source_hash":"94652ae4","tags":[],"deepnote_cell_type":"code"},"source":"# at max_itr = 1000, it does not converge\nres = imdb_df_CV.kfoldCV(\n    LogisticRegression(solver=\"newton-cg\", max_iter=1000, n_jobs=4, tol=0.01),\n    TfidfVectorizer(),\n)\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:36:26 Starting CV 0/5 Test_Set[0:10000]\nINFO:root:2021-02-22 00:36:42 Starting CV 1/5 Test_Set[10000:20000]\nINFO:root:2021-02-22 00:36:58 Starting CV 2/5 Test_Set[20000:30000]\nINFO:root:2021-02-22 00:37:14 Starting CV 3/5 Test_Set[30000:40000]\nINFO:root:2021-02-22 00:37:30 Starting CV 4/5 Test_Set[40000:50000]\nINFO:root:ACC: avg: 0.90436, [0.8995, 0.9079, 0.9047, 0.9029, 0.9068]\nINFO:root:ERR: avg: 0.09564, [0.1005, 0.0921, 0.0953, 0.0971, 0.0932]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00034-2f96d651-5f44-4b2c-99f5-1d0782c02be8","tags":[],"deepnote_to_be_reexecuted":true,"source_hash":"d30e936e","execution_millis":285612,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = imdb_df_CV.kfoldCV_custom_size(\n        LogisticRegression(solver=\"newton-cg\", max_iter=1000, n_jobs=4, tol=0.01),\n        TfidfVectorizer(),\n        i,\n    )\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:37:46 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:37:58 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:38:10 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:38:22 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:38:34 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.882495, [0.8838, 0.88295, 0.882025, 0.8811, 0.8826]\nINFO:root:ERR: avg: 0.117505, [0.1162, 0.11705, 0.117975, 0.1189, 0.1174]\nINFO:root:2021-02-22 00:38:46 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:39:00 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:39:13 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:39:26 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:39:39 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.89484, [0.8954333333333333, 0.8939333333333334, 0.8958333333333334, 0.8944, 0.8946]\nINFO:root:ERR: avg: 0.10516, [0.10456666666666667, 0.10606666666666667, 0.10416666666666667, 0.1056, 0.1054]\nINFO:root:2021-02-22 00:39:53 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:40:08 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:40:23 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:40:39 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:40:55 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.90079, [0.89895, 0.90155, 0.90215, 0.9017, 0.8996]\nINFO:root:ERR: avg: 0.09921, [0.10105, 0.09845, 0.09785, 0.0983, 0.1004]\nINFO:root:2021-02-22 00:41:09 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:41:26 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:41:43 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:41:59 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:42:16 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.90538, [0.9073, 0.9061, 0.9042, 0.9044, 0.9049]\nINFO:root:ERR: avg: 0.09462, [0.0927, 0.0939, 0.0958, 0.0956, 0.0951]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Twenty News Group","metadata":{"cell_id":"00017-9fa40160-3f45-443b-8264-f03adc2412be","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00019-5e4e937e-0e7b-428c-8a67-30b80f1ffcdd","deepnote_to_be_reexecuted":true,"execution_millis":0,"output_cleared":false,"source_hash":"83d08ae9","tags":[],"deepnote_cell_type":"code"},"source":"# tol=1e-4 takes forever to converge soooo don't do it :)\n# takes forever to train, uncomment when ready\n\n# res = twenty_CV.kfoldCV(\n#     LogisticRegression(solver=\"newton-cg\", n_jobs=4, tol=0.1), CountVectorizer()\n# )\n# print_acc_err(res)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00028-ad0bfdd4-40a4-4b63-8d7a-bf8c7939e019","deepnote_to_be_reexecuted":true,"execution_millis":339756,"source_hash":"7c58d74f","tags":[],"deepnote_cell_type":"code"},"source":"res = twenty_CV.kfoldCV(\n    LogisticRegression(solver=\"newton-cg\", max_iter=1000, n_jobs=4), TfidfVectorizer()\n)\nprint_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:42:32 Starting CV 0/5 Test_Set[0:3770]\nINFO:root:2021-02-22 00:43:46 Starting CV 1/5 Test_Set[3770:7540]\nINFO:root:2021-02-22 00:44:46 Starting CV 2/5 Test_Set[7540:11310]\nINFO:root:2021-02-22 00:46:06 Starting CV 3/5 Test_Set[11310:15080]\nINFO:root:2021-02-22 00:47:11 Starting CV 4/5 Test_Set[15080:18850]\nINFO:root:ACC: avg: 0.7331556253002222, [0.7381962864721485, 0.7244031830238726, 0.7281167108753316, 0.7291777188328913, 0.7458842272968667]\nINFO:root:ERR: avg: 14.847590855497534, [14.191511936339522, 15.988063660477454, 15.856233421750662, 14.430238726790451, 13.77190653212958]\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"cell_id":"00038-b57f1e78-aa4c-4d10-8f4f-317f8c9a4511","tags":[],"deepnote_to_be_reexecuted":true,"source_hash":"9a8a930d","execution_millis":492985,"deepnote_cell_type":"code"},"source":"for i in [0.2, 0.4, 0.6, 0.8]:\n    res = twenty_CV.kfoldCV_custom_size(\n        LogisticRegression(solver=\"newton-cg\", n_jobs=4, tol=0.1), TfidfVectorizer(), i\n    )\n    print_acc_err(res)","execution_count":null,"outputs":[{"name":"stderr","text":"INFO:root:2021-02-22 00:48:11 Starting CV 0/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:48:21 Starting CV 1/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:48:31 Starting CV 2/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:48:40 Starting CV 3/5 Train=0.2, Test=0.8\nINFO:root:2021-02-22 00:48:50 Starting CV 4/5 Train=0.2, Test=0.8\nINFO:root:ACC: avg: 0.6568946076805731, [0.6535782980699079, 0.6455528288120979, 0.6590170458313989, 0.6580884791404126, 0.6682363865490483]\nINFO:root:ERR: avg: 17.288028122305498, [19.29879949592094, 16.615772368508324, 16.646945678848578, 16.59958877760828, 17.279034290641373]\nINFO:root:2021-02-22 00:48:58 Starting CV 0/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:49:14 Starting CV 1/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:49:31 Starting CV 2/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:49:47 Starting CV 3/5 Train=0.4, Test=0.6\nINFO:root:2021-02-22 00:50:06 Starting CV 4/5 Train=0.4, Test=0.6\nINFO:root:ACC: avg: 0.7007251503360453, [0.6995932083480721, 0.698001414927485, 0.7071100106119561, 0.7011850017686594, 0.6977361160240537]\nINFO:root:ERR: avg: 15.951503360452778, [15.805624336752741, 15.784311991510435, 15.779978776087725, 15.474000707463743, 16.91360099044924]\nINFO:root:2021-02-22 00:50:23 Starting CV 0/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:50:50 Starting CV 1/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:51:17 Starting CV 2/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:51:50 Starting CV 3/5 Train=0.6, Test=0.4\nINFO:root:2021-02-22 00:52:19 Starting CV 4/5 Train=0.6, Test=0.4\nINFO:root:ACC: avg: 0.7266383656142212, [0.7252586893075086, 0.7215441761740514, 0.7291058636243035, 0.7259219952241974, 0.7313611037410453]\nINFO:root:ERR: avg: 14.908463783496948, [14.611435394003715, 15.403289997346777, 15.14009020960467, 15.140886176704695, 14.246617139824886]\nINFO:root:2021-02-22 00:52:48 Starting CV 0/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:53:32 Starting CV 1/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:54:18 Starting CV 2/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:54:58 Starting CV 3/5 Train=0.8, Test=0.19999999999999996\nINFO:root:2021-02-22 00:55:35 Starting CV 4/5 Train=0.8, Test=0.19999999999999996\nINFO:root:ACC: avg: 0.7325019899177501, [0.7306977978243566, 0.7336163438577872, 0.7309631201910322, 0.7368002122578934, 0.7304324754576811]\nINFO:root:ERR: avg: 15.07768638896259, [14.674449456089148, 16.283894932342797, 13.942159724064739, 14.667551074555584, 15.820376757760679]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Code archives 😀","metadata":{"cell_id":"00014-5dbe2371-9ccc-4bb5-ab15-0e84c1199711","tags":[],"deepnote_cell_type":"markdown"}},{"cell_type":"code","metadata":{"cell_id":"00007-60dfb7aa-3bc5-481c-a43b-1b7fc4e4fab7","deepnote_to_be_reexecuted":true,"execution_millis":0,"source_hash":"503655f0","tags":[],"deepnote_cell_type":"code"},"source":"# batches = []\n\n# for X, y in BatchTraining(imdb_test_X, imdb_test_y, vect):\n#     y_predicted = nb.predict(X)\n#     batches.append(evaluate_acc(y, y_predicted))\n\n# sum(batches) / len(batches)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00010-6bb3cd9f-537e-43ec-8ba3-ad31869504c2","deepnote_to_be_reexecuted":true,"execution_millis":0,"source_hash":"40b4ea91","tags":[],"deepnote_cell_type":"code"},"source":"# imdb_train_X, imdb_test_X, imdb_train_y, imdb_test_y = train_test_split_df(imdb_df)\n\n# vect = TfidfVectorizer(min_df=5)\n# imdb_tfidf_vect = vect.fit_transform(imdb_train_X)\n\n\n# NB_model = NaiveBayes()\n# # Cross Validation Phase\n# #crossed_dataset_split_x, crossed_dataset_split_y = CrossValidation.cross_validation_split(imdb_tfidf_vect, imdb_train_y)\n\n# err_valid = CrossValidation.kfoldCV(imdb_tfidf_vect, imdb_train_y, NB_model)\n# print(err_valid)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"00007-db426637-3cdd-4cd6-a2ea-7be8bd6a7812","deepnote_to_be_reexecuted":true,"execution_millis":4,"source_hash":"99d96606","tags":[],"deepnote_cell_type":"code"},"source":"# loss = lambda y, yh: np.mean((y - yh) ** 2)\n\n\n# class CrossValidation:\n#     def __init__(self):\n#         return\n\n#     # That 'probably' more efficient method\n#     def cross_validation_split(dataset_x, n_folds=3):\n#         n = len(dataset_x)\n#         n_val = n // n_folds\n#         inds = np.random.permutation(n)\n#         inds = []\n#         for f in range(n_folds):\n#             tr_inds = []\n#             # get the validation indexes\n#             val_inds = list(range(f * n_val, (f + 1) * n_val))\n#             # get the train indexes\n#             if f > 0:\n#                 tr_inds = list(range(f * n_val))\n#             if f < n_folds - 1:\n#                 tr_inds = tr_inds + list(range((f + 1) * n_val, n))\n#             # The yield statement suspends function’s execution and sends a value back to the caller\n#             # but retains enough state information to enable function to resume where it is left off\n#             yield tr_inds, val_inds\n\n#     # Self-implemented\n#     def kfoldCV(dataset_x, dataset_y, model, folds=3):\n#         err_valid = np.zeros(folds)\n#         for f, (tr, val) in enumerate(cross_validate(dataset_x, folds)):\n#             model = model.fit(np.array(dataset_x[tr]), np.array(dataset_y[tr]))\n#             err_valid[f] = loss(\n#                 np.array(dataset_y[val]), model.predict(np.array(dataset_x[val]))\n#             )\n\n#     def repeat(self):\n#         pass","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f5e36ec1-5982-458d-86cb-de064c0212ca' target=\"_blank\">\n<img style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":2,"metadata":{"deepnote":{"is_reactive":false},"deepnote_execution_queue":[],"deepnote_notebook_id":"9478e254-f0ab-4204-a510-7de08e23442c"}}